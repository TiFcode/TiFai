{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TiFcode/TiFai/blob/main/TiFai_tif3_object_recognition_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJ7jXFizJg0o"
      },
      "outputs": [],
      "source": [
        "print('*** START PROGRAM ********************************************************')\n",
        "\n",
        "outputDetails = False\n",
        "outputInfo = True\n",
        "outputEpochs = False\n",
        "outputConvolutionOutput = False\n",
        "image_pixels_X = 224\n",
        "image_pixels_Y = 224\n",
        "googleDriveFolderPath = '/content/drive/My Drive/Personal/Dev/ChatGPT/2023-01-05 - AI - object recognition/'\n",
        "# see the cell below for help on setting the value for googleDriveFolderPath"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To get the value for googleDriveFolderPath, you can use the following code, then comment back this cell.\n",
        "\n",
        "\"\"\"\n",
        "from google.colab import drive\n",
        "import glob\n",
        "drive.mount('/content/drive')\n",
        "pattern = '/content/drive/My Drive/**/*20230105_151957.jpg'\n",
        "filenames = glob.glob(pattern, recursive=True)\n",
        "print(filenames)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "EMlX91fGU8Jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkqvccAKKb3Y"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def display_image(image, description):\n",
        "  print(f'{description}:')\n",
        "  print(f'Image size: {image.shape}')\n",
        "  cv2_imshow(image)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "\n",
        "def retrieve_variable_name_from_local(var):\n",
        "    callers_local_vars = inspect.currentframe().f_back.f_locals.items()\n",
        "    return [var_name for var_name, var_val in callers_local_vars if var_val is var]\n",
        "    \n",
        "def retrieve_variable_name_from_call(var):\n",
        "    callers_local_vars = inspect.currentframe().f_back.f_back.f_locals.items()\n",
        "    return [var_name for var_name, var_val in callers_local_vars if var_val is var]\n",
        "\n",
        "def textForVar(variable):\n",
        "  return f'{retrieve_variable_name_from_call(variable)} is [{variable}]'\n",
        "\n",
        "def textForVarWithDesc(variable, description):\n",
        "  return f'{description} is [{variable}]'\n",
        "\n",
        "def printInfo(text):\n",
        "  if outputInfo:\n",
        "    print(text)"
      ],
      "metadata": {
        "id": "51X1PO_Wzagb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZH-iBWjQiJy"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import glob\n",
        "!pwd\n",
        "!ls\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "!pwd\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoXS308mLQwY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "def loadAndProcessAllFilesFromFolder(folderPath):\n",
        "  filenames = os.listdir(folderPath)\n",
        "\n",
        "  imagesArray = []\n",
        "  for filename in filenames:\n",
        "    filenameFullPath = folderPath + filename\n",
        "    if outputDetails:\n",
        "      print(f'Found file [{filename}] with size [{os.stat(filenameFullPath).st_size}] bytes.')\n",
        "    \n",
        "    image = cv2.imread(filenameFullPath)\n",
        "    if outputDetails:\n",
        "      display_image(image, filenameFullPath)\n",
        "    imagesArray.append(image)\n",
        "\n",
        "    if outputDetails:\n",
        "      print(f'imagesArray contains [{len(imagesArray)}] elements.')\n",
        "\n",
        "  # Convert the images to a format that can be used as input to a CNN\n",
        "  imagesArray = [cv2.cvtColor(image, cv2.COLOR_BGR2RGB) for image in imagesArray]\n",
        "\n",
        "  return imagesArray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZm0IuQUKvyW"
      },
      "outputs": [],
      "source": [
        "def load_images(folderName):\n",
        "  print(f'Loading {folderName}...')\n",
        "  images = loadAndProcessAllFilesFromFolder(googleDriveFolderPath + folderName + '/')\n",
        "  print(f'{folderName} contains [{len(images)}] images.')\n",
        "  return images\n",
        "\n",
        "training_images_yes = load_images('training_images_yes')\n",
        "training_images_non = load_images('training_images_non')\n",
        "validation_images_yes = load_images('validation_images_yes')\n",
        "validation_images_non = load_images('validation_images_non')\n",
        "search_images = load_images('search_images')\n",
        "\n",
        "print('*** FINISH LOADING IMAGES ********************************************************')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the object images automatically into a training set and a validation set\n",
        "X_train, X_val = train_test_split(object_images, test_size=0.2, random_state=42)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "m0uEZhnNxZM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def prepare_array(list_of_images):\n",
        "  print(f'START: Preparing array [{retrieve_variable_name_from_call(list_of_images)}] ...')\n",
        "\n",
        "  # Convert the list to numpy array\n",
        "  printInfo(textForVarWithDesc(type(list_of_images), \"type(list_of_images)\"))\n",
        "  printInfo(textForVarWithDesc(len(list_of_images), \"len(list_of_images)\"))\n",
        "  array_of_images = np.array(list_of_images)\n",
        "  printInfo(textForVarWithDesc(type(array_of_images), \"type(array_of_images)\"))\n",
        "  printInfo(textForVarWithDesc(array_of_images.shape[0], \"array_of_images.shape[0]\"))\n",
        "\n",
        "  printInfo(textForVarWithDesc(array_of_images.shape, \"array_of_images.shape\"))\n",
        "\n",
        "  print(f'END: Preparing array [{retrieve_variable_name_from_call(list_of_images)}].\\n\\n\\n')\n",
        "\n",
        "  return array_of_images\n",
        "\n",
        "# Preparing the image arrays\n",
        "training_images_yes = prepare_array(training_images_yes)\n",
        "training_images_non = prepare_array(training_images_non)\n",
        "validation_images_yes = prepare_array(validation_images_yes)\n",
        "validation_images_non = prepare_array(validation_images_non)\n",
        "\n",
        "target_labels_of_training_images_yes = np.ones(training_images_yes.shape[0])\n",
        "target_labels_of_training_images_non = np.zeros(training_images_non.shape[0])\n",
        "target_labels_of_validation_images_yes = np.ones(validation_images_yes.shape[0])\n",
        "target_labels_of_validation_images_non = np.zeros(validation_images_non.shape[0])\n",
        "\n",
        "training_images = np.concatenate((training_images_yes, training_images_non))\n",
        "validation_images = np.concatenate((validation_images_yes, validation_images_non))\n",
        "target_labels_of_training_images = np.concatenate((target_labels_of_training_images_yes, target_labels_of_training_images_non))\n",
        "target_labels_of_validation_images = np.concatenate((target_labels_of_validation_images_yes, target_labels_of_validation_images_non))\n",
        "\n",
        "search_images = prepare_array(search_images)\n",
        "\n",
        "printInfo(textForVarWithDesc(training_images.shape, \"training_images.shape\"))\n",
        "printInfo(textForVarWithDesc(validation_images.shape, \"validation_images.shape\"))\n",
        "printInfo(textForVarWithDesc(target_labels_of_training_images.shape, \"target_labels_of_training_images.shape\"))\n",
        "printInfo(textForVarWithDesc(target_labels_of_validation_images.shape, \"target_labels_of_validation_images.shape\"))\n",
        "printInfo(textForVarWithDesc(search_images.shape, \"search_images.shape\"))\n"
      ],
      "metadata": {
        "id": "LdlmykJG9uwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.models import Sequential\n",
        "\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(image_pixels_X, image_pixels_Y, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "training_batch_size = training_images.shape[0]\n",
        "if outputEpochs:\n",
        "  verbose=1\n",
        "else:\n",
        "  verbose=0\n",
        "\n",
        "history = model.fit(training_images, target_labels_of_training_images, batch_size=training_batch_size, epochs=100, validation_data=(validation_images, target_labels_of_validation_images), verbose=verbose)\n"
      ],
      "metadata": {
        "id": "SxhcN2KApGo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "PKACC4-Y2oG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualize the features extracted by a convolutional neural network (CNN), we can use the matplotlib library to plot the feature maps produced by the filters in the different layers of the CNN.\n",
        "\n",
        "In this example, the feature maps are extracted from the CNN by creating a new model that maps the input to the feature maps produced by the convolutional layer. The feature maps are then predicted for a given input image and plotted using imshow(). We can adjust the number of rows and columns in the plot by changing the values of 8 and 4 in the subplot() function."
      ],
      "metadata": {
        "id": "OHZAEAtc2_pv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(training_images[0]) "
      ],
      "metadata": {
        "id": "k6E1A1gu4WjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if outputConvolutionOutput:\n",
        "  # Import the necessary modules\n",
        "  import matplotlib.pyplot as plt\n",
        "  from keras.models import Model\n",
        "\n",
        "  # Extract the feature maps from the CNN\n",
        "  feature_maps = model.get_layer('conv2d').output\n",
        "\n",
        "  # Create a model that maps the input to the feature maps\n",
        "  feature_map_model = Model(inputs=model.input, outputs=feature_maps)\n",
        "\n",
        "  # Use the model to predict the feature maps for an input image\n",
        "  input_image = np.expand_dims(training_images[0], axis=0)\n",
        "  feature_maps = feature_map_model.predict(input_image)\n"
      ],
      "metadata": {
        "id": "ruKBk5kc2-Z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if outputConvolutionOutput:\n",
        "  print(textForVarWithDesc(len(feature_maps[0]), 'len(feature_maps[0])'))\n",
        "\n",
        "  # Plot the feature maps\n",
        "  for i, feature_map in enumerate(feature_maps[0]):\n",
        "    #plt.subplot(56, 4, i + 1)\n",
        "    print(textForVarWithDesc(i, '\\n\\nValue of i'))\n",
        "    #plt.figure(figsize=(10, 5))\n",
        "    #plt.imshow(feature_map, cmap='gray')\n",
        "\n",
        "    print(textForVarWithDesc(feature_map.shape, 'feature_map.shape'))\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(15, 0.5))\n",
        "    ax.imshow(feature_map, cmap='plasma', aspect='auto')\n",
        "\n",
        "    plt.show()\n",
        "    #break"
      ],
      "metadata": {
        "id": "_BfakNuNNMuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualize the training history, we use the matplotlib library to plot the training and validation accuracy and loss over time:"
      ],
      "metadata": {
        "id": "etQB7V3N1D6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Import the necessary modules\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract the training and validation accuracy and loss\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Create the plot\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()"
      ],
      "metadata": {
        "id": "0fZeALNF0-8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3Ue7csbjtCyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions for the search images\n",
        "predictions = model.predict(search_images)"
      ],
      "metadata": {
        "id": "irGKRm2utS2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the threshold\n",
        "threshold = 0.5\n",
        "\n",
        "# Loop through the predictions\n",
        "for i in range(len(predictions)):\n",
        "  cv2_imshow(search_images[i])\n",
        "  print(textForVarWithDesc(predictions[i], f'Search image number {i} -> predictions[{i}]'))\n",
        "  # If the prediction is greater than the threshold, print \"Object found\"\n",
        "  if predictions[i] > threshold:\n",
        "    print(f\"=> The confidence is higher than {threshold * 100}% that there is SOMETHING in the search image number {i}\\n\\t\\t\\t\\t\\t\\t\\tthat is SIMILAR to the training images.\\n\\n\\n\\n\\n\")\n",
        "  # Otherwise, print \"Object not found\"\n",
        "  else:\n",
        "    print(f\"Confidence lower than {threshold * 100}% \\n\\n\\n\\n\\n\")\n"
      ],
      "metadata": {
        "id": "EypvSAqAE4qF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('*** END PROGRAM ********************************************************')\n"
      ],
      "metadata": {
        "id": "XVrHcDtgWeMO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "history_visible": true,
      "authorship_tag": "ABX9TyPKUruPGMjebKBtlZ1GBney",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}