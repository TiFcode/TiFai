{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TiFcode/TiFai/blob/main/TiFai_tif3_object_recognition_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJ7jXFizJg0o"
      },
      "outputs": [],
      "source": [
        "print('*** START ********************************************************')\n",
        "\n",
        "!pwd\n",
        "!ls\n",
        "\n",
        "outputDetails = False\n",
        "outputInfo = True\n",
        "size = (224, 224)\n",
        "googleDriveFolderPath = '/content/drive/My Drive/Personal/Dev/ChatGPT/2023-01-05 - AI - object recognition/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkqvccAKKb3Y"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def display_image(image, description):\n",
        "  print(f'{description}:')\n",
        "  print(f'Image size: {image.shape}')\n",
        "  cv2_imshow(image)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import inspect\n",
        "\n",
        "def retrieve_variable_name_from_local(var):\n",
        "    callers_local_vars = inspect.currentframe().f_back.f_locals.items()\n",
        "    return [var_name for var_name, var_val in callers_local_vars if var_val is var]\n",
        "    \n",
        "def retrieve_variable_name_from_call(var):\n",
        "    callers_local_vars = inspect.currentframe().f_back.f_back.f_locals.items()\n",
        "    return [var_name for var_name, var_val in callers_local_vars if var_val is var]\n",
        "\n",
        "def textForVar(variable):\n",
        "  return f'{retrieve_variable_name_from_call(variable)} is [{variable}]'\n",
        "\n",
        "def textForVarWithDesc(variable, description):\n",
        "  return f'{description} is [{variable}]'\n",
        "\n",
        "def printInfo(text):\n",
        "  if outputInfo:\n",
        "    print(text)"
      ],
      "metadata": {
        "id": "51X1PO_Wzagb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZH-iBWjQiJy"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import glob\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "!pwd\n",
        "!ls\n",
        "\n",
        "# Search for a file by name\n",
        "#pattern = '/content/drive/My Drive/**/*20230105_151957.jpg'\n",
        "#filenames = glob.glob(pattern, recursive=True)\n",
        "#print(filenames)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoXS308mLQwY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "def loadAndProcessAllFilesFromFolder(folderPath):\n",
        "  filenames = os.listdir(folderPath)\n",
        "\n",
        "  imagesArray = []\n",
        "  for filename in filenames:\n",
        "    filenameFullPath = folderPath + filename\n",
        "    if outputDetails:\n",
        "      print(f'Found file [{filename}] with size [{os.stat(filenameFullPath).st_size}] bytes.')\n",
        "    \n",
        "    image = cv2.imread(filenameFullPath)\n",
        "    if outputDetails:\n",
        "      display_image(image, filenameFullPath)\n",
        "    imagesArray.append(image)\n",
        "\n",
        "    if outputDetails:\n",
        "      print(f'imagesArray contains [{len(imagesArray)}] elements.')\n",
        "\n",
        "  # Resize the images to a fixed size\n",
        "  imagesArray = [cv2.resize(image, size) for image in imagesArray]\n",
        "\n",
        "  # Convert the images to a format that can be used as input to a CNN\n",
        "  imagesArray = [cv2.cvtColor(image, cv2.COLOR_BGR2RGB) for image in imagesArray]\n",
        "\n",
        "  return imagesArray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZm0IuQUKvyW"
      },
      "outputs": [],
      "source": [
        "def load_images(folderName):\n",
        "  print(f'Loading {folderName}...')\n",
        "  images = loadAndProcessAllFilesFromFolder(googleDriveFolderPath + folderName + '/')\n",
        "  print(f'{folderName} contains [{len(images)}] images.')\n",
        "  return images\n",
        "\n",
        "training_images = load_images('training_images')\n",
        "validation_images = load_images('validation_images')\n",
        "search_images = load_images('search_images')\n",
        "\n",
        "print('*** FINISH LOADING IMAGES ********************************************************')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the object images into a training set and a validation set\n",
        "#X_train, X_val = train_test_split(object_images, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "m0uEZhnNxZM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def prepare_array(list_of_images):\n",
        "  print(f'START: Preparing array [{retrieve_variable_name_from_call(list_of_images)}] ...')\n",
        "\n",
        "  # Convert the list to numpy array\n",
        "  printInfo(textForVarWithDesc(type(list_of_images), \"type(list_of_images)\"))\n",
        "  printInfo(textForVarWithDesc(len(list_of_images), \"len(list_of_images)\"))\n",
        "  array_of_images = np.array(list_of_images)\n",
        "  printInfo(textForVarWithDesc(type(array_of_images), \"type(array_of_images)\"))\n",
        "  printInfo(textForVarWithDesc(array_of_images.shape[0], \"array_of_images.shape[0]\"))\n",
        "\n",
        "  # Reshape the array\n",
        "  printInfo(textForVarWithDesc(array_of_images.shape, \"array_of_images.shape\"))\n",
        "  #batch_size = array_of_images.shape[0]\n",
        "  #printInfo(textForVar(batch_size))\n",
        "  #array_of_images = np.reshape(array_of_images, (batch_size, 224, 224, 3))\n",
        "  #printInfo(textForVarWithDesc(array_of_images.shape, \"array_of_images.shape\"))\n",
        "\n",
        "  print(f'END: Preparing array [{retrieve_variable_name_from_call(list_of_images)}].')\n",
        "\n",
        "  return array_of_images\n",
        "\n",
        "\n",
        "# Preparing the image arrays\n",
        "training_images = prepare_array(training_images)\n",
        "validation_images = prepare_array(validation_images)\n",
        "search_images = prepare_array(search_images)\n",
        "\n",
        "# Create the target data\n",
        "target_data_yes = np.ones(training_images.shape[0])\n",
        "target_data_no = np.zeros(training_images.shape[0])\n",
        "target_data = target_data_yes"
      ],
      "metadata": {
        "id": "LdlmykJG9uwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.models import Sequential\n",
        "\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "training_batch_size = training_images.shape[0]\n",
        "history = model.fit(training_images, target_data, batch_size=training_batch_size, epochs=10, validation_data=(validation_images,))\n"
      ],
      "metadata": {
        "id": "SxhcN2KApGo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions for the search images\n",
        "predictions = model.predict(search_images)\n",
        "\n",
        "# Set the threshold\n",
        "threshold = 0.5\n",
        "\n",
        "# Loop through the predictions\n",
        "for i in range(len(predictions)):\n",
        "  cv2_imshow(search_images[i])\n",
        "  print(textForVarWithDesc(predictions[i], 'predictions[i]'))\n",
        "  # If the prediction is greater than the threshold, print \"Object found\"\n",
        "  if predictions[i] > threshold:\n",
        "    print(f\"=> Object found in search image {i}\\n\\n\\n\")\n",
        "  # Otherwise, print \"Object not found\"\n",
        "  else:\n",
        "    print(f\"Object not found in search image {i}\\n\\n\\n\")\n"
      ],
      "metadata": {
        "id": "EypvSAqAE4qF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "history_visible": true,
      "authorship_tag": "ABX9TyMmtZELJtoVOcJ+J9nC2FAv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}